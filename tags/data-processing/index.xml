<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Processing on D0CUM3NTN4T10N</title>
    <link>https://documentnation.github.io/tags/data-processing/</link>
    <description>Recent content in Data Processing on D0CUM3NTN4T10N</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 06 Dec 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://documentnation.github.io/tags/data-processing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Data Manipulation for Machine Learning</title>
      <link>https://documentnation.github.io/docs/hdks/machine-learning/data-processing/data-manipulation-for-machine-learning/</link>
      <pubDate>Wed, 06 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://documentnation.github.io/docs/hdks/machine-learning/data-processing/data-manipulation-for-machine-learning/</guid>
      <description>Prepare Dataset linkBefore manipulation, load dataset as DataFrame as Pandas.&#xA;import pandas as pd df = pd.read_csv(&amp;#39;example.csv&amp;#39;, index_col=0) Data Analysis linkBefore attacking, need to investigate the dataset and find the points where we can manipulate and fool models and people.&#xA;# Information df.info() # Dimensionality df.shape # Data types df.dtypes # Correlation of Columns df.corr # Histgram df.hist() Access Values link # The first 5 rows df.head() df.iloc[:5] df.iloc[:5].values # as NumPy # The first 10 rows df.</description>
    </item>
    <item>
      <title>Dimensionality Reduction for Machine Learning</title>
      <link>https://documentnation.github.io/docs/hdks/machine-learning/data-processing/dimensionality-reduction-for-machine-learning/</link>
      <pubDate>Sun, 20 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://documentnation.github.io/docs/hdks/machine-learning/data-processing/dimensionality-reduction-for-machine-learning/</guid>
      <description>PCA (Principal Component Analysis) linkReference: https://www.kaggle.com/code/jonbown/ai-ctf-submissions?scriptVersionId=105606691&amp;amp;cellId=42&#xA;we use PCA to find the optimal dimensions for data.&#xA;import numpy as np from sklearn.decomposition import PCA data = np.load(&amp;#34;example.npy&amp;#34;) for i in range(1, 10): pca = PCA(n_components=i) principal_components = pca.fit_transform(data) print(pca.explained_variance_ratio_) </description>
    </item>
  </channel>
</rss>
